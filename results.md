```py
#0.925
n_qubits = 4                # Number of qubits
step = 0.0004               # Learning rate
batch_size = 4              # Number of samples for each training step
num_epochs = 10         # Number of training epochs
q_depth = 6                 # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.935
n_qubits = 4                # Number of qubits
step = 0.0007               # Learning rate
batch_size = 4              # Number of samples for each training step
num_epochs = 3          # Number of training epochs
q_depth = 4                 # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01
```
```
#0.92
n_qubits = 4                # Number of qubits
step = 0.001               # Learning rate
batch_size = 8              # Number of samples for each training step
num_epochs = 3          # Number of training epochs
q_depth = 5                 # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.95
n_qubits = 4                # Number of qubits
step = 0.0005               # Learning rate
batch_size = 6              # Number of samples for each training step
num_epochs = 6          # Number of training epochs
q_depth = 5                 # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.95
n_qubits = 4                # Number of qubits
step = 0.0005               # Learning rate
batch_size = 6              # Number of samples for each training step
num_epochs = 10          # Number of training epochs
q_depth = 5                 # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.935 in resnet18 and resnet34
n_qubits = 4                # Number of qubits
step = 0.001               # Learning rate
batch_size = 4              # Number of samples for each training step
num_epochs = 8          # Number of training epochs
q_depth = 5                 # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
start_time = time.time()    # Start of the computation timer
```
```
#0.94 in resnet34
n_qubits = 4                # Number of qubits
step = 0.0005               # Learning rate
batch_size = 8              # Number of samples for each training step
num_epochs = 8          # Number of training epochs
q_depth = 6                # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.925 in resnet34
n_qubits = 4                # Number of qubits
step = 0.0001               # Learning rate
batch_size = 10              # Number of samples for each training step
num_epochs = 15          # Number of training epochs
q_depth = 5                # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.945 in resnet34
n_qubits = 4                # Number of qubits
step = 0.0008               # Learning rate
batch_size = 6              # Number of samples for each training step
num_epochs = 6          # Number of training epochs
q_depth = 5                # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
```
#0.875 in resnet18
n_qubits = 4                # Number of qubits
step = 0.00005               # Learning rate
batch_size = 6              # Number of samples for each training step
num_epochs = 6          # Number of training epochs
q_depth = 5                # Depth of the quantum circuit (number of variational layers)
gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.
q_delta = 0.01              # Initial spread of random quantum weights
```
